---
layout: archive
permalink: /experience/
author_profile: true
redirect_from: 
  - /experience.html

---

{% include base_path %}

# Education
<span style="color:gray"><small>Sep 2010 - Feb 2019</small></span>  
**Combined M.S. and Ph.D., Electrical and Electronic Engineering, [Yonsei University](https://www.yonsei.ac.kr/en_sc/index.jsp), Seoul, Korea**  
<small>
  &nbsp;&nbsp;&bull; Dissertation: Improved time-frequency trajectory excitation vocoder for deep learning-based statistical parametric speech synthesis system  
  &nbsp;&nbsp;&bull; Advisor : Prof. [Hong-Goo Kang](http://dsp.yonsei.ac.kr/)  
</small>

<span style="color:gray"><small>Mar 2006 - Aug 2010</small></span>  
**B.S., Electrical and Electronic Engineering, [Yonsei University](https://www.yonsei.ac.kr/en_sc/index.jsp), Souel, Korea**  

***
# Work Experience
<span style="color:gray"><small>Jan 2023 - Present</small></span>  
**Senior research scientist, Voice Synthesis team lead, [Naver Cloud](https://navercloudcorp.com/lang/en/), Seongnam, Korea**  
<small>
  &nbsp;&nbsp;&bull; Research and development of deep learning-based TTS models  
  &nbsp;&nbsp;&bull; Implementing TTS api for cloud services such as [Clova Voice Pro](https://www.ncloud.com/product/aiService/clovaVoice), [Clova Dubbing](https://clovadubbing.naver.com/), and [Voice Maker](https://clovadubbing.naver.com/voicemaker)   
  &nbsp;&nbsp;&bull; **<strong style="color:orange">Specialities:</strong>** High-quality neural vocoders and controllable TTS models  
</small>

<span style="color:gray"><small>Aug 2022 - Present</small></span>  
**Adjunct professor, [Artificial Intelligence Institute](https://aiis.snu.ac.kr/eng/), [SNU](https://en.snu.ac.kr/index.html), Seoul, Korea**  

<span style="color:gray"><small>Mar 2017 - Dec 2022</small></span>  
**Senior research scientist, Voice Model team lead, [Clova Voice](https://clova.ai/ko), [Naver Corp.](https://www.navercorp.com/en), Seongnam, Korea**  
<small>
  &nbsp;&nbsp;&bull; Research and development of TTS system combining deep learning and unit-selection TTS models  
  &nbsp;&nbsp;&bull; Implementing cloud-based real-time TTS products for [Clova AI speaker](https://blog.naver.com/clova_ai/221409341851), [Maps navigation](https://blog.naver.com/naver_map/222109060982), and [News anchor](https://blog.naver.com/clova_ai/221981676372)   
</small>

<span style="color:gray"><small>Aug 2016 - Nov 2016</small></span>  
**Research Intern, [Qualcomm Technologies Inc.](https://www.qualcomm.com/company?#about), San Diego, CA**  
<small>
  &nbsp;&nbsp;&bull; Spatial audio: Fixed-point implementation of MPEG-H 3D Audio Decoder  
  &nbsp;&nbsp;&bull; Mentor: Dr. [Deep Sen](https://www.researchgate.net/profile/Deep-Sen)  
</small>

<span style="color:gray"><small>Sep 2015 - Feb 2016, Apr 2016 - Jun 2016</small></span>  
**Research Intern, [Microsoft Research Asia](https://www.microsoft.com/en-us/research/lab/microsoft-research-asia/), Beijing, China**  
<small>
  &nbsp;&nbsp;&bull; Speech synthesis: Deep learning-based TTS system using ITFTE vocoder  
  &nbsp;&nbsp;&bull; Mentor: Dr. [Frank Soong](https://www.researchgate.net/profile/Frank-Soong)  
</small>

<small>[[See more]]({{ base_path }}/projects/)</small>  

***
# Academic Activites
**Reviewer**  
<small>
  &nbsp;&nbsp;&bull; **Signal Processing Letters** 2023  
  &nbsp;&nbsp;&bull; **INTERSPEECH** 2020 - 2025  
  &nbsp;&nbsp;&bull; **ICASSP** 2021 - 2025  
</small>

***
# Honors and Awards
<small>
  &nbsp;&nbsp;&bull; **[Innovators Under 35 Korea](https://www.innovatorsunder35.com/the-list/eunwoo-song/)**, MIT Technology Review, Dec 2022  
  &nbsp;&nbsp;&bull; **Ranked No. 2, N Innovation Award 2020**, Naver Corp., Dec 2020  
  &nbsp;&nbsp;&bull; **The Best Paper Award**, APSIPA ASC 2020, Dec 2020  
  &nbsp;&nbsp;&bull; **Ranked No. 1, N Innovation Award 2019**, Naver Corp., Dec 2019  
  &nbsp;&nbsp;&bull; **Ranked No. 1, N Innovation Award 2018**, Naver Corp., Nov 2018  
  &nbsp;&nbsp;&bull; **Excellent Intern Award**, Microsoft Research Asia, Jun 2016  
  &nbsp;&nbsp;&bull; **Excellent Intern Award**, Microsoft Research Asia, Feb 2016  
</small>

***
# Patents
<small>
  &nbsp;&nbsp;&bull; [KR10-2742631](https://doi.org/10.8080/1020230016624), **Method, computer device, and computer program for pruning self-attention for speaker-adaptive text-to-speech system**, Dec 2024  
  &nbsp;&nbsp;&bull; [KR10-2663162](https://doi.org/10.8080/1020220117469), **Method and system for synthesizing speech**, Apr 2024  
  &nbsp;&nbsp;&bull; [KR10-2661751](https://doi.org/10.8080/1020220116409), **Method and system for generating speech synthesis model based on selective data augmentation**, Apr 2024  
  &nbsp;&nbsp;&bull; [KR10-2626618](https://doi.org/10.8080/1020220047188), **Method and system for synthesizing emotional speech based on emotion prediction**, Jan 2024  
  &nbsp;&nbsp;&bull; [KR10-2621842](https://doi.org/10.8080/1020210115859), **Method and system for non-autoregressive speech synthesis**, Jan 2024  
  &nbsp;&nbsp;&bull; [KR10-2198598](https://doi.org/10.8080/1020190004085), **Method for generating synthesized speech signal, neural vocoder, and training method thereof**, Dec 2020  
  &nbsp;&nbsp;&bull; [KR10-2198597](https://doi.org/10.8080/1020190004084), **Neural vocoder and training method of neural vocoder for constructing speaker-adaptive model**, Dec 2020  
</small>
